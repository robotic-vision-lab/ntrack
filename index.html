<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="A multiple-object tracker and dataset for infield cotton boll counting.">
  <meta name="keywords" content="computer vision, multi-object tracking, agriculture, cotton">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>NTrack: A Multiple-Object Tracker and Dataset for Infield Cotton Boll Counting</title>
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-G98Z7CL7LN"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-G98Z7CL7LN');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">NTrack: A Multiple-Object Tracker and Dataset for Infield Cotton Boll Counting</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"> Md Ahmed Al Muzaddid and <a href="https://ranger.uta.edu/~wjbeksi">William J. Beksi</a></span>
          </div>
          <div class="is-size-5 publication-university">
            <span class="author-block">The University of Texas at Arlington</span>
          </div>
          <div class="is-size-5 publication-lab">
            <span class="author-block">
              <a href="https://rvl.uta.edu">Robotic Vision Laboratory</a></span>
          </div>
          <div class="column is-centered">
            <div class="publication-links">
              <!-- Paper link -->
              <span class="link-block">
                <a href="https://ieeexplore.ieee.org/document/10367844" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Preprint link -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2312.10922.pdf" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Preprint</span>
                </a>
              </span>
              <!-- Presentation link -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=ol-wLw-gUgU&t=16s" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Presentation</span>
                </a>
              </span>
              <!-- Source code link -->
              <span class="link-block">
                <a href="https://github.com/robotic-vision-lab/NTrack-A-Multiple-Object-Tracker" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Source Code</span>
                </a>
              </span>
              <!-- Dataset link -->
              <span class="link-block">
                <a href="" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">

        <div class="item vid16_01_raw">
          <video poster="" id="raw" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/cotton_cam_view.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item vid16_01_detection">
          <video poster="" id="detection" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/vid16_01_detection.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item vid16_01_tracking">
          <video poster="" id="tracking" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/vid16_01_tracking.mp4" type="video/mp4">
          </video>
        </div>

	    <div class="item vid26_03_raw">
          <video poster="" id="raw" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/vid26_03_raw_compressed.mp4" type="video/mp4">
          </video>
        </div>

         <div class="item vid26_03_detection">
          <video poster="" id="detection" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/vid26_03_detection_compressed.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item vid26_03_tracking">
          <video poster="" id="tracking" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/vid26_03_track_compressed.mp4" type="video/mp4">
          </video>
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop" id="Abstract">
    <div class="columns is-centered">
      <!-- Abstract -->
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In agriculture, automating the accurate tracking of fruits,
            vegetables, and fiber is a very tough problem. The issue becomes
            extremely challenging in dynamic field environments. Yet, this
            information is critical for making day-to-day agricultural
            decisions, assisting breeding programs, and much more.  To tackle
            this dilemma, we introduce <strong>NTrack</strong>, a novel
            multiple object tracking framework based on the linear
            relationship between the locations of <em>neighboring</em>
            tracks. <strong>NTrack</strong> computes dense optical flow and
            utilizes particle filtering to guide each tracker.
            Correspondences between detections and tracks are found through
            data association via direct observations and indirect cues, which
            are then combined to obtain an updated observation. Our modular
            multiple object tracking system is independent of the underlying
            detection method, thus allowing for the interchangeable use of
            any off-the-shelf object detector.  We show the efficacy of our
            approach on the task of tracking and counting infield cotton
            bolls.  Experimental results show that our system exceeds
            contemporary tracking and cotton boll-based counting methods by a
            large margin.  Furthermore, we publicly release the
            <em>first</em> annotated cotton boll video dataset to the
            research community.
          </p>
        </div>
      </div>
    </div>
  </div>
  <br>

  <div class="container is-max-desktop" id="Dataset">
    <div class="columns is-centered">
      <!-- Dataset -->
      <div class="column is-full-width">
        <h2 class="title is-3">Dataset</h2>
        <div class="content has-text-justified">
          <p>
            The <strong>TexCot22</strong> dataset is a set of cotton crop
            video sequences for training and testing multi-object tracking
            methods.  Each tracking sequence is 10 to 20 seconds in length.
            The dataset contains of a total of 30 sequences of which 17 are
            for training and the remaining 13 are for testing. The video
            sequences were captured at 4K resolution and at distinct frame
            rates (e.g., 10, 15, 30).  There are typically 2 to 10 cotton
            bolls per cluster. The average width and height of an annotated
            bounding box is approximately 230 x 210 pixels. To make the
            dataset robust to environmental conditions, we recorded the field
            videos at separate times of day to account for varying lighting
            conditions. In total, there are roughly 30 x 300 frames with
            150,000 labeled instances. On average there are 70 unique cotton
            bolls in each sequence.
          </p>
        </div>
      </div>
    </div>
  </div>
  <br>

  <div class="container is-max-desktop content" id="Citation">
    <!-- Citation -->
    <h2 class="title is-3">Citation</h2>
    <p>
      If you find this project useful, then please consider citing both our
      paper and dataset.
    </p>
    <pre><code>@article{muzaddid2023ntrack,
  title={NTrack: A Multiple-Object Tracker and Dataset for Infield Cotton Boll Counting},
  author={Al Muzaddid, Md Ahmed and Beksi, William J},
  journal={IEEE Transactions on Automation Science and Engineering},
  volume={},
  pages={},
  doi={10.1109/TASE.2023.3342791},
  year={2023}
}</code></pre>
    <pre><code>@misc{muzaddid2023texcot22,
  title={TexCot22},
  author={Al Muzaddid, Md Ahmed and Beksi, William J},
  publisher={Texas Data Repository},
  version={1},
  url={https://doi.org/10.18738/T8/5M9NCI},
  doi={10.18738/T8/5M9NCI},
  year={2023}
}</code></pre>
  </div>
  <br>

  <div class="container is-max-desktop" id="License">
    <div class="columns is-centered">
      <!-- License-->
      <div class="column is-full-width">
        <h2 class="title is-3">License</h2>
        <div class="content has-text-justified">
          <p>
            <strong>NTrack</strong> is licensed under the 
            <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License, Version 2.0</a>.  
            The <strong>TexCot22</strong> dataset is available for non-commercial use under the 
            <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License ("CC BY-NC-SA 4.0")</a>. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a 
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>. 
            This means you are free to borrow the 
            <a href="https://github.com/robotic-vision-lab/ntrack">source code</a>
            of this website, we just ask that you link back to this page in the
            footer. Please remember to remove the analytics code included in
            the header of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
